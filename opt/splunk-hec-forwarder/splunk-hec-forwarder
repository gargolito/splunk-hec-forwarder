#!/usr/bin/env python
# these are supposed to help with cpu util.
from __future__ import print_function
from __future__ import division
# System modules
import os
import sys
import Queue
import threading
import argparse
import requests
import urllib
import time
import socket
import uuid
import logging
from requests.adapters import HTTPAdapter
from requests.packages.urllib3.util.retry import Retry
# uncomment to debug http requests
# import httplib
# httplib.HTTPConnection.debuglevel = 1

requests.packages.urllib3.disable_warnings()

_LOG_LEVEL_STRINGS = ['CRITICAL', 'ERROR', 'WARNING', 'INFO', 'DEBUG']


def _logLevel_string_to_int(logLevel_string):
    if logLevel_string not in _LOG_LEVEL_STRINGS:
        message = 'invalid choice: {0} (choose from {1})'.format(
            logLevel_string, _LOG_LEVEL_STRINGS)
        raise argparse.ArgumentTypeError(message)
    logLevel_int = getattr(logging, logLevel_string, logging.DEBUG)
    assert isinstance(logLevel_int, int)
    return logLevel_int


host = socket.gethostname()
default_logName = "splunk_hec_fwd-" + host + ".log"

parser = argparse.ArgumentParser()
parser.add_argument("-t", "--token", help="hec token.", required=True)
parser.add_argument("-s", "--server", help="hec splunk server fqdn.", required=True)
parser.add_argument('--host', help="default host name is "+host, default=host)
parser.add_argument('-p', '--port', help="hec splunk server port. (default = 8088)", default='8088')
parser.add_argument('--ssl', help="use ssl.", action='store_true', default=False)
parser.add_argument('--sslNoverify', help="disable ssl validation.", action='store_false', default=False)
parser.add_argument('--source', help="default source name is hec:syslog", default="hec:syslog:" + host)
parser.add_argument('--sourcetype', help="default sourcetype is syslog", default="syslog")
parser.add_argument('--index', help="index name. (default = main)", default="main")
parser.add_argument('-mb','--maxBatch', help="max number of records allowed in one batch of requests for hec. (default = 50)", default=50, type=int)
parser.add_argument('-mq','--maxQueue', help="max number of records to be read from rsyslog queued for transfer. (default = 5000)", default=5000, type=int)
parser.add_argument('-mr','--maxRetry', help="max attempts to post log lines to splunk hec. (default = 5)", default=5, type=int)
parser.add_argument('-mt','--maxThreads', help="max number of threads for work. (default = 4)", default=4, type=int)
parser.add_argument('-up','--udpPort', help="udp port that script will listen to syslog (default = 55514)", default=55514, type=int)
parser.add_argument('--logDir', help="log directory. (default = /var/log)", default="/var/log/", type=str)
parser.add_argument('--logName', help="log file name. (default = splunk_hec_fwd-hostname.log", default=default_logName, type=str)
parser.add_argument('--logLevel', default='ERROR',
                    dest='logLevel', type=_logLevel_string_to_int, nargs='?',
                    help='Set the logging output level. {0}.'.format(_LOG_LEVEL_STRINGS))
args = parser.parse_args()


if args.logName:
    if ".log" not in args.logName:
        args.logName = args.logName + ".log"
    else:
        args.logName = default_logName

logger = logging.getLogger('splunk-hec-fwd')
logger.setLevel(args.logLevel)
fi = logging.FileHandler(
    os.path.join(args.logDir, args.logName)
)
fi.setLevel(args.logLevel)
formatter = logging.Formatter(
    '%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
fi.setFormatter(formatter)
logger.addHandler(fi)


def onReceive(threadID, mq, tq, evt):
    """
    This is the entry point where actual work needs to be done. It receives
    a list with all messages received from rsyslog. The list is of variable
    length, but contains all messages that are currently available.
    """
    with requests.Session() as s:
        # requests module built in retry: will retry args.maxRetry (default 5) times,
        # then backoff {backoff factor} * (2 ^ ({total_retries} - 1))
        retries = Retry(total=args.maxRetry,
                        backoff_factor=0.2,
                        status_forcelist=[500, 502, 503, 504],
                        method_whitelist=frozenset(['GET', 'POST'])
                        )

        if args.ssl:
            protocol = 'https'
            s.mount('https://', HTTPAdapter(max_retries=retries))
        else:
            protocol = 'http'
            s.mount('http://', HTTPAdapter(max_retries=retries))

        session_id = str(uuid.uuid1())
        headers = {'Authorization': 'Splunk '+args.token}

        querystring = urllib.urlencode(
            {'channel': session_id,
             'source': args.source,
             'sourcetype': args.sourcetype,
             'index': args.index,
             'host': args.host}
        )

        server_uri = '%s://%s:%s/services/collector/raw?%s' % (protocol, args.server, args.port, querystring)
        logger.debug('TheadID %s' % (threadID))
        logger.debug('server_uri =  %s' % (server_uri))
        while not evt.is_set() or not mq.empty():
            c = 0
            data = []
            sl = 0
            while sl < 2 and c < args.maxBatch:
                try:
                    m = mq.get(True, 1)
                    if m:
                        logger.debug('msg =  %s' % (m.replace('\n', '')))
                        c = c+1
                        data.append(m)
                        mq.task_done()
                except Queue.Empty:
                    sl = sl+1
                    logger.debug("empty queue sleeping")
                    time.sleep(.1)
            # Place one event in the batch
            if c > 0:
                bail = False
                max_retry = args.maxRetry
                time.sleep(.05)
                logger.debug("sending %s events" % (c))
                d = "".join(data)
                while max_retry and not bail:
                    try:
                        # timeout 1 means wait to connect 1 seconds and for response 1 seconds.
                        # 3 to connect is the tcp default. but we can pass timeout=(1, 2) if we want
                        # to wait 1 sec to connect and 2 sec to response from server
                        r = s.post(server_uri, data=d, headers=headers, verify=args.sslNoverify, timeout=1)
                        if r.status_code == 200:
                            if max_retry is not args.maxRetry:
                                logger.warning("RETRY #: %s" % (max_retry))
                                logger.warning("RETRY SUCCEEDED: %s" % (r.status_code))
                            logger.debug("POST SUCCEEDED: %s" % (r.status_code))
                            logger.debug("r = %s" % (r.text))
                            bail = True
                        r.raise_for_status()
                    except requests.exceptions.RequestException as http_error:
                        logger.warning("HTTP_ERROR: %s" % (http_error))
                        logger.warning('FAILED TO SEND:\n%s' % (m.replace('\n', '')))
                        logger.warning("RETRYING %s TIMES AFTER ERROR..." % (max_retry))
                        max_retry -= 1
                        if not max_retry:
                            logger.error("RETRY FAILED WITH HTTP_ERROR: %s, AFTER %s ATTEMPTS" % (http_error, max_retry))
                            logger.error("r = %s" % (r.text))
                            bail = True
                        time.sleep(.05)
                        continue
            else:
                logger.info("sending 0")
        tq.get()
        tq.task_done()


# the syslog listener
UDP_IP_ADDRESS = "127.0.0.1"
UDP_PORT_NO = args.udpPort
# listening serverSocket
serverSock = socket.socket(socket.AF_INET, socket.SOCK_DGRAM)
# bind serverSocket
serverSock.bind((UDP_IP_ADDRESS, UDP_PORT_NO))

stop_event = threading.Event()
# stop_event.set()
maxAtOnce = args.maxBatch
msgQueue = Queue.Queue(maxsize=args.maxQueue)
threadQueue = Queue.Queue(maxsize=args.maxThreads)
for i in range(args.maxThreads):
    threadQueue.put(i)
    worker = threading.Thread(
        target=onReceive, args=(i, msgQueue, threadQueue, stop_event)
    )
    worker.setDaemon(True)
    worker.start()
while not stop_event.is_set():
    while not stop_event.is_set() and serverSock:
        line, addr = serverSock.recvfrom(8192)
        if line:
            msgQueue.put(line)
            logger.debug(line.replace('\n', ''))
        else:  # an empty line means stdin has been closed
            logger.info('end of rsyslog events to process')
            stop_event.set()
            msgQueue.join()
            logger.info('msgQueue joined')
logger.info('waiting for thread shutdown')
threadQueue.join()
sys.stdout.flush()  # very important, Python buffers far too much!

